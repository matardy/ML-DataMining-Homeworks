{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matardy/ML-DataMining-Homeworks/blob/master/notebooks/12_AdvancedRNN_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c656e2f",
      "metadata": {
        "id": "8c656e2f"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, LSTM, Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b6ed4902",
      "metadata": {
        "id": "b6ed4902"
      },
      "outputs": [],
      "source": [
        "max_features = 5000  # Number of words to consider as features\n",
        "max_len_short = 100  # Maximum sequence length for short sequences\n",
        "max_len_long = 500   # Maximum sequence length for long sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "70a1d987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70a1d987",
        "outputId": "9f293226-14ba-4b3e-da8f-7d7c03ae7b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf4562a7",
      "metadata": {
        "id": "cf4562a7"
      },
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "x_train_short = pad_sequences(x_train, maxlen=max_len_short)\n",
        "x_test_short = pad_sequences(x_test, maxlen=max_len_short)\n",
        "x_train_long = pad_sequences(x_train, maxlen=max_len_long)\n",
        "x_test_long = pad_sequences(x_test, maxlen=max_len_long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a05de3a3",
      "metadata": {
        "id": "a05de3a3"
      },
      "outputs": [],
      "source": [
        "# Define models\n",
        "def build_elman_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32))\n",
        "    model.add(SimpleRNN(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "22fb38b1",
      "metadata": {
        "id": "22fb38b1"
      },
      "outputs": [],
      "source": [
        "def build_jordan_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32))\n",
        "    model.add(SimpleRNN(32, activation='relu', return_sequences=True))\n",
        "    model.add(SimpleRNN(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36ba83c5",
      "metadata": {
        "id": "36ba83c5"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2afe01cd",
      "metadata": {
        "id": "2afe01cd"
      },
      "outputs": [],
      "source": [
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "018b8923",
      "metadata": {
        "id": "018b8923"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate each model\n",
        "models = {\"Elman RNN\": build_elman_rnn_model, \"Jordan RNN\": build_jordan_rnn_model, \"LSTM\": build_lstm_model}\n",
        "data = {\"short sequences\": (x_train_short, x_test_short), \"long sequences\": (x_train_long, x_test_long)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "737e8218",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737e8218",
        "outputId": "021c0f06-3ac0-4e85-9ae1-2ffcef05023c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Elman RNN on short sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 8s 44ms/step - loss: 0.6116 - acc: 0.6592 - val_loss: 0.5093 - val_acc: 0.7482\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3993 - acc: 0.8260 - val_loss: 0.3737 - val_acc: 0.8342\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 0.3230 - acc: 0.8651 - val_loss: 0.5287 - val_acc: 0.7904\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2970 - acc: 0.8758 - val_loss: 0.3736 - val_acc: 0.8388\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.2689 - acc: 0.8913 - val_loss: 0.3645 - val_acc: 0.8396\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 0.2553 - acc: 0.8967 - val_loss: 0.4253 - val_acc: 0.8394\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 5s 34ms/step - loss: 0.2352 - acc: 0.9061 - val_loss: 0.3670 - val_acc: 0.8462\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.2275 - acc: 0.9090 - val_loss: 0.3728 - val_acc: 0.8452\n",
            "Evaluating Elman RNN on short sequences...\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.3738 - acc: 0.8460\n",
            "Test loss: 0.3738\n",
            "Test accuracy: 0.8460\n",
            "Training Elman RNN on long sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 31s 187ms/step - loss: 0.6638 - acc: 0.5993 - val_loss: 0.5474 - val_acc: 0.7728\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 27s 175ms/step - loss: 0.4835 - acc: 0.7918 - val_loss: 0.5594 - val_acc: 0.7268\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 29s 182ms/step - loss: 0.3798 - acc: 0.8446 - val_loss: 0.3361 - val_acc: 0.8610\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 27s 173ms/step - loss: 0.3222 - acc: 0.8766 - val_loss: 0.3520 - val_acc: 0.8468\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 27s 173ms/step - loss: 0.3359 - acc: 0.8911 - val_loss: 0.3048 - val_acc: 0.8706\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 27s 172ms/step - loss: 0.2567 - acc: 0.9025 - val_loss: 0.3181 - val_acc: 0.8634\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 27s 172ms/step - loss: 0.2447 - acc: 0.9071 - val_loss: 0.3362 - val_acc: 0.8520\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 29s 187ms/step - loss: 0.2347 - acc: 0.9136 - val_loss: 0.4632 - val_acc: 0.8298\n",
            "Evaluating Elman RNN on long sequences...\n",
            "782/782 [==============================] - 21s 26ms/step - loss: 0.4706 - acc: 0.8283\n",
            "Test loss: 0.4706\n",
            "Test accuracy: 0.8283\n",
            "Training Jordan RNN on short sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 14s 75ms/step - loss: 0.6530 - acc: 0.6457 - val_loss: 0.5178 - val_acc: 0.7862\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 12s 77ms/step - loss: 0.4518 - acc: 0.8033 - val_loss: 0.3895 - val_acc: 0.8254\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.3744 - acc: 0.8398 - val_loss: 0.3810 - val_acc: 0.8266\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 12s 76ms/step - loss: 0.3342 - acc: 0.8620 - val_loss: 0.4166 - val_acc: 0.8142\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 12s 75ms/step - loss: 0.3089 - acc: 0.8714 - val_loss: 0.4746 - val_acc: 0.8128\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 12s 74ms/step - loss: 0.2847 - acc: 0.8827 - val_loss: 0.3542 - val_acc: 0.8470\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 13s 81ms/step - loss: 0.2710 - acc: 0.8921 - val_loss: 0.4422 - val_acc: 0.7990\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 11s 67ms/step - loss: 0.2553 - acc: 0.9000 - val_loss: 0.3665 - val_acc: 0.8352\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.2320 - acc: 0.9087 - val_loss: 0.4105 - val_acc: 0.8422\n",
            "Evaluating Jordan RNN on short sequences...\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4171 - acc: 0.8387\n",
            "Test loss: 0.4171\n",
            "Test accuracy: 0.8387\n",
            "Training Jordan RNN on long sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 55s 337ms/step - loss: 0.6752 - acc: 0.5685 - val_loss: 0.6077 - val_acc: 0.6678\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 54s 346ms/step - loss: 0.5114 - acc: 0.7581 - val_loss: 0.4128 - val_acc: 0.8188\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 52s 333ms/step - loss: 0.4082 - acc: 0.8268 - val_loss: 0.3902 - val_acc: 0.8294\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 52s 334ms/step - loss: 0.3679 - acc: 0.8559 - val_loss: 0.3728 - val_acc: 0.8366\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 53s 340ms/step - loss: 0.3385 - acc: 0.8721 - val_loss: 0.4833 - val_acc: 0.7962\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 52s 332ms/step - loss: 0.6479 - acc: 0.8795 - val_loss: 0.6234 - val_acc: 0.8326\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 52s 333ms/step - loss: 0.2759 - acc: 0.8969 - val_loss: 0.5814 - val_acc: 0.7862\n",
            "Evaluating Jordan RNN on long sequences...\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.5711 - acc: 0.7854\n",
            "Test loss: 0.5711\n",
            "Test accuracy: 0.7854\n",
            "Training LSTM on short sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 17s 97ms/step - loss: 0.5737 - acc: 0.6912 - val_loss: 0.4427 - val_acc: 0.8242\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 13s 81ms/step - loss: 0.3670 - acc: 0.8412 - val_loss: 0.3569 - val_acc: 0.8478\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 0.3093 - acc: 0.8733 - val_loss: 0.3674 - val_acc: 0.8408\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 13s 83ms/step - loss: 0.2805 - acc: 0.8857 - val_loss: 0.3706 - val_acc: 0.8456\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 13s 83ms/step - loss: 0.2623 - acc: 0.8977 - val_loss: 0.3652 - val_acc: 0.8408\n",
            "Evaluating LSTM on short sequences...\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3632 - acc: 0.8386\n",
            "Test loss: 0.3632\n",
            "Test accuracy: 0.8386\n",
            "Training LSTM on long sequences...\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 62s 379ms/step - loss: 0.6047 - acc: 0.6587 - val_loss: 0.4270 - val_acc: 0.8266\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 58s 365ms/step - loss: 0.3738 - acc: 0.8482 - val_loss: 0.3235 - val_acc: 0.8686\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 59s 377ms/step - loss: 0.2908 - acc: 0.8848 - val_loss: 0.3543 - val_acc: 0.8454\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 56s 354ms/step - loss: 0.2571 - acc: 0.9007 - val_loss: 0.3598 - val_acc: 0.8432\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 58s 368ms/step - loss: 0.2380 - acc: 0.9090 - val_loss: 0.3102 - val_acc: 0.8628\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 56s 358ms/step - loss: 0.2212 - acc: 0.9180 - val_loss: 0.2906 - val_acc: 0.8820\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 59s 376ms/step - loss: 0.2064 - acc: 0.9237 - val_loss: 0.3142 - val_acc: 0.8664\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 56s 358ms/step - loss: 0.1964 - acc: 0.9276 - val_loss: 0.3865 - val_acc: 0.8454\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 59s 378ms/step - loss: 0.1833 - acc: 0.9334 - val_loss: 0.3151 - val_acc: 0.8786\n",
            "Evaluating LSTM on long sequences...\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.3291 - acc: 0.8768\n",
            "Test loss: 0.3291\n",
            "Test accuracy: 0.8768\n"
          ]
        }
      ],
      "source": [
        "for model_name, model_builder in models.items():\n",
        "    for data_name, (x_train, x_test) in data.items():\n",
        "        print(f\"Training {model_name} on {data_name}...\")\n",
        "        model = model_builder()\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "        print(f\"Evaluating {model_name} on {data_name}...\")\n",
        "        loss, acc = model.evaluate(x_test, y_test)\n",
        "        print(f\"Test loss: {loss:.4f}\")\n",
        "        print(f\"Test accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d57dc49",
      "metadata": {
        "id": "2d57dc49"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}